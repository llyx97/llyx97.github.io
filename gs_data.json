{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "pLOm4rYAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Yuanxin Liu", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=pLOm4rYAAAAJ&citpid=4", "affiliation": "Peking University", "organization": 10725744176602846184, "interests": ["Natural Language Processing"], "email_domain": "@stu.pku.edu.cn", "homepage": "https://llyx97.github.io/", "citedby": 1134, "publications": {"pLOm4rYAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Tempcompass: Do video llms really understand videos?", "pub_year": "2024"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:hqOjcs7Dif8C", "num_citations": 177, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11817956159221163179,16718026192557813584,9269659314909901494", "cites_id": ["11817956159221163179", "16718026192557813584", "9269659314909901494"]}, "pLOm4rYAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Aligning visual regions and textual concepts for semantic-grounded image representations", "pub_year": "2019"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:d1gkVwhDpl0C", "num_citations": 146, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2159125820163720413,9173674357976862635", "cites_id": ["2159125820163720413", "9173674357976862635"]}, "pLOm4rYAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "simnet: Stepwise image-topic merging network for generating detailed and comprehensive image captions", "pub_year": "2018"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:9yKSN-GCB0IC", "num_citations": 124, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5709649317619862029", "cites_id": ["5709649317619862029"]}, "pLOm4rYAAAAJ:ULOm3_A8WrAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Kimi-vl technical report", "pub_year": "2025"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:ULOm3_A8WrAC", "num_citations": 118, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7327189826770849230,15045540419272305770,783499239337750126,637654964577818367,6873221216160166042", "cites_id": ["7327189826770849230", "15045540419272305770", "783499239337750126", "637654964577818367", "6873221216160166042"]}, "pLOm4rYAAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Fetv: A benchmark for fine-grained evaluation of open-domain text-to-video generation", "pub_year": "2023"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:UebtZRa9Y70C", "num_citations": 94, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16797871499191104183", "cites_id": ["16797871499191104183"]}, "pLOm4rYAAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Exploring and distilling cross-modal information for image captioning", "pub_year": "2020"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:u5HHmVD_uO8C", "num_citations": 86, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13329023829002422855", "cites_id": ["13329023829002422855"]}, "pLOm4rYAAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Deco: Decoupling token compression from semantic abstraction in multimodal large language models", "pub_year": "2024"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:5nxA0vEk-isC", "num_citations": 81, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16315909502816627502", "cites_id": ["16315909502816627502"]}, "pLOm4rYAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards robust visual question answering: Making the most of biased samples via contrastive learning", "pub_year": "2022"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:_FxGoFyzp5QC", "num_citations": 40, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15087191019749082650", "cites_id": ["15087191019749082650"]}, "pLOm4rYAAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Vitatecs: A diagnostic dataset for temporal concept understanding of video-language models", "pub_year": "2024"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:0EnyYjriUFMC", "num_citations": 39, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1988283831992714017", "cites_id": ["1988283831992714017"]}, "pLOm4rYAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Language prior is not the only shortcut: A benchmark for shortcut learning in vqa", "pub_year": "2022"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:LkGwnXOMwfcC", "num_citations": 36, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2105777161210243794", "cites_id": ["2105777161210243794"]}, "pLOm4rYAAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Self-adaptive scaling for learnable residual structure", "pub_year": "2019"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:W7OEmFMy1HYC", "num_citations": 26, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17790918364311479917", "cites_id": ["17790918364311479917"]}, "pLOm4rYAAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rosita: Refined bert compression with integrated techniques", "pub_year": "2021"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:zYLM7Y9cAGgC", "num_citations": 24, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=141946000252938968", "cites_id": ["141946000252938968"]}, "pLOm4rYAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Generating paraphrase with topic as prior knowledge", "pub_year": "2019"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:u-x6o8ySG0sC", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1925416115148640484", "cites_id": ["1925416115148640484"]}, "pLOm4rYAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Connecting targets via latent topics and contrastive learning: A unified framework for robust zero-shot and few-shot stance detection", "pub_year": "2022"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:WF5omc3nYNoC", "num_citations": 18, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1174931634700723396", "cites_id": ["1174931634700723396"]}, "pLOm4rYAAAAJ:ZeXyd9-uunAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SpaceR: Reinforcing MLLMs in Video Spatial Reasoning", "pub_year": "2025"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:ZeXyd9-uunAC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17987681924264595015,10679311388685173025", "cites_id": ["17987681924264595015", "10679311388685173025"]}, "pLOm4rYAAAAJ:MXK_kJrjxJIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Temporal reasoning transfer from text to video", "pub_year": "2024"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:MXK_kJrjxJIC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2970488385762800496", "cites_id": ["2970488385762800496"]}, "pLOm4rYAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning to win lottery tickets in BERT transfer via task-agnostic mask training", "pub_year": "2022"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:eQOLeE2rZwMC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10681388987449318576", "cites_id": ["10681388987449318576"]}, "pLOm4rYAAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Unsupervised pre-training for natural language generation: A literature review", "pub_year": "2019"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:IjCSPb-OGe4C", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2512364126262955483", "cites_id": ["2512364126262955483"]}, "pLOm4rYAAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning class-transductive intent representations for zero-shot intent detection", "pub_year": "2020"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:YsMSGLbcyi4C", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9100737528742736579", "cites_id": ["9100737528742736579"]}, "pLOm4rYAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Ranking and sampling in open-domain question answering", "pub_year": "2019"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:UeHWp8X0CEIC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5473614580487966446", "cites_id": ["5473614580487966446"]}, "pLOm4rYAAAAJ:KlAtU1dfN6UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TimeChat-Online: 80% Visual Tokens are Naturally Redundant in Streaming Videos", "pub_year": "2025"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:KlAtU1dfN6UC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17760526836769717785", "cites_id": ["17760526836769717785"]}, "pLOm4rYAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A win-win deal: Towards sparse and robust pre-trained language models", "pub_year": "2022"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:ufrVoPGSRksC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12965321937141963299", "cites_id": ["12965321937141963299"]}, "pLOm4rYAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Marginal Utility Diminishes: Exploring the Minimum Knowledge for BERT Knowledge Distillation", "pub_year": "2021"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:Tyk-4Ss8FVUC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1922667977439296686", "cites_id": ["1922667977439296686"]}, "pLOm4rYAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Cost-eff: Collaborative optimization of spatial and temporal efficiency with slenderized multi-exit language models", "pub_year": "2022"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:roLk4NBRz8UC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14246026446941228580", "cites_id": ["14246026446941228580"]}, "pLOm4rYAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards multimodal video paragraph captioning models robust to missing modality", "pub_year": "2024"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:8k81kl-MbHgC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17659477999738976586", "cites_id": ["17659477999738976586"]}, "pLOm4rYAAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Compressing and debiasing vision-language pre-trained models for visual question answering", "pub_year": "2022"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:Se3iqnhoufwC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7546977239770852905", "cites_id": ["7546977239770852905"]}, "pLOm4rYAAAAJ:YOwf2qJgpHMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VideoReasonBench: Can MLLMs Perform Vision-Centric Complex Video Reasoning?", "pub_year": "2025"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:YOwf2qJgpHMC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9945701699478372343", "cites_id": ["9945701699478372343"]}, "pLOm4rYAAAAJ:aqlVkmm33-oC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "RICO: Improving Accuracy and Completeness in Image Recaptioning via Visual Reconstruction", "pub_year": "2025"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:aqlVkmm33-oC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=922126954188814658", "cites_id": ["922126954188814658"]}, "pLOm4rYAAAAJ:Zph67rFs4hoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TEMPLE: Temporal Preference Learning of Video LLMs via Difficulty Scheduling and Pre-SFT Alignment", "pub_year": "2025"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:Zph67rFs4hoC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16073179297651550590", "cites_id": ["16073179297651550590"]}, "pLOm4rYAAAAJ:3fE2CSJIrl8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "UVE: Are MLLMs Unified Evaluators for AI-Generated Videos?", "pub_year": "2025"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:3fE2CSJIrl8C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15243075108714963158", "cites_id": ["15243075108714963158"]}, "pLOm4rYAAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PunchBench: Benchmarking MLLMs in Multimodal Punchline Comprehension", "pub_year": "2024"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:kNdYIx-mwKoC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9873537563279325381", "cites_id": ["9873537563279325381"]}, "pLOm4rYAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning Disentangled Intent Representations for Zero-shot Intent Detection.", "pub_year": "2012"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:Y0pCki6q_DkC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3744170661735523851", "cites_id": ["3744170661735523851"]}}, "citedby5y": 1111, "hindex": 15, "hindex5y": 15, "i10index": 17, "i10index5y": 17, "cites_per_year": {"2019": 19, "2020": 51, "2021": 115, "2022": 114, "2023": 91, "2024": 216, "2025": 524}, "updated": "2025-10-19 08:00:54.838162"}